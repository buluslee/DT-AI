{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 双向长短时记忆网络（BiLSTM）详细介绍\n",
    "\n",
    "双向长短时记忆网络（BiLSTM）是一种强大的循环神经网络（RNN）架构，用于处理序列数据并捕获过去和未来时间步的信息。在NLP和其他序列数据任务中，BiLSTM广泛应用，以下是更详细的介绍：\n",
    "\n",
    "## LSTM 简要回顾\n",
    "\n",
    "在传统的LSTM中，信息从过去流向现在，其中包含了三个关键部分：遗忘门、输入门和输出门。这些门控制着信息的流动，使LSTM能够更好地处理长距离依赖关系。\n",
    "\n",
    "## BiLSTM 架构\n",
    "\n",
    "BiLSTM通过在每个时间步使用两个隐藏层，实现了正向和反向的信息传递。这允许模型同时考虑过去和未来的上下文，从而更好地理解序列数据。\n",
    "双向长短时记忆网络（BiLSTM）是一种序列模型，用于处理输入序列，并输出包含了该序列信息的序列。对于每个位置的输出，\n",
    "它会包含该位置的信息以及之前的信息。换句话说，普通的LSTM能够捕获位置 t 以及之前位置的信息。而对于双向LSTM（BiLSTM），它能够捕获位置 t 的双向信息。\n",
    "如果是BiLSTM，它的每个位置的输出是前向LSTM的输出 y → 与反向LSTM的输出 y ← 拼接在一起，[ y → ; y ← ]。\n",
    "因此，假设你设置LSTM的隐藏层维度为128，那么单向LSTM的输出维度是128，但是双向LSTM的输出维度是256（128*2）。\n",
    "然而，尽管LSTM声称可以捕获长距离依赖信息，实际上这种能力存在争议。在实际应用中，LSTM的性能可能不如其声称的那么出色。\n",
    "有研究表明，LSTM在捕获长距离依赖信息方面甚至不如卷积神经网络（CNN）。\n",
    "\n",
    "\n",
    "\n",
    "以下是BiLSTM的架构示意图：\n",
    "\n",
    "<img src=\"../img/20181013173510909.jpg\" alt=\"RNN Cell\" width=\"800\"/>\n",
    "\n",
    "1. **输入层**：序列数据（如文本或语音）被转换为向量形式，作为输入提供给网络。\n",
    "\n",
    "2. **正向LSTM层**：正向处理输入序列，每个时间步的隐藏状态都包含过去的信息。\n",
    "\n",
    "3. **反向LSTM层**：反向处理输入序列，每个时间步的隐藏状态都包含未来的信息。\n",
    "\n",
    "4. **连接层**：正向和反向LSTM层的输出在每个时间步连接在一起，形成综合的双向上下文表示。\n",
    "\n",
    "5. **输出层**：连接后的表示可用于各种任务，如分类、生成等。\n",
    "\n",
    "## 应用领域示例\n",
    "\n",
    "BiLSTM在自然语言处理（NLP）和其他序列数据任务中表现出色：\n",
    "\n",
    "- **情感分析**：通过考虑上下文，BiLSTM能更好地理解情感表达。\n",
    "- **命名实体识别**：BiLSTM能捕捉上下文中实体的上下文信息，从而提高识别准确性。\n",
    "- **语音识别**：在语音信号处理中，BiLSTM对捕获声学特征的双向依赖关系非常有用。\n",
    "\n",
    "## 总结\n",
    "\n",
    "双向长短时记忆网络（BiLSTM）是一种强大的RNN架构，通过同时考虑过去和未来的上下文信息，能够更好地处理序列数据任务。在NLP和其他需要捕获双向依赖性的任务中，BiLSTM发挥着重要作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BiLSTM 实现情感分析\n",
    "全部代码在 github 上，网址为：https://github.com/Balding-Lee/Pytorch4NLP\n",
    "我采用的是 IMDb 数据集，由于数据集没有验证集，而且读取起来很麻烦，所以我将数据给读取出来，放到了一个文件中，并且将训练集中的10%划分为了验证集，数据集链接如下： https://pan.baidu.com/s/128EYenTiEirEn0StR9slqw ，提取码：xtu3 。\n",
    "采用的词嵌入是谷歌的词嵌入，词嵌入的链接如下：链接：https://pan.baidu.com/s/1SPf8hmJCHF-kdV6vWLEbrQ ，提取码：r5vx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 代码在github的nlp的code/BiLSTM中"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}