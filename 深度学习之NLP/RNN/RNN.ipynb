{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，以下是更加详细的循环神经网络（RNN）介绍文档：\n",
    "\n",
    "# 循环神经网络（RNN）介绍\n",
    "\n",
    "## 什么是循环神经网络？\n",
    "\n",
    "循环神经网络（Recurrent Neural Network，RNN）是一种深度学习模型，专门设计用于处理序列数据，例如时间序列、自然语言、音频信号等。相较于传统的前馈神经网络，RNN 具备一种独特的结构，使得网络可以在处理序列数据时在不同时间步之间共享信息，从而更好地捕捉序列中的时间相关性和模式。\n",
    "\n",
    "## RNN 的结构和工作原理\n",
    "\n",
    "RNN 的核心思想是引入循环结构，使得网络在每个时间步都可以接收当前时间步的输入和上一个时间步的隐藏状态。这使得网络具有了一种记忆能力，可以将之前时间步的信息传递到后续时间步中。\n",
    "\n",
    "RNN 的一个基本单元如下图所示：\n",
    "\n",
    "![RNN Cell](img/1.png)\n",
    "\n",
    "在上图中，`Xt` 表示输入序列在时间步 t 的输入，`at` 表示在时间步 t 的隐藏状态，`Yt` 表示在时间步 t 的输出。RNN 在每个时间步都执行相同的操作，输入数据和上一个时间步的隐藏状态通过权重矩阵进行组合，并经过激活函数（通常为 tanh 或 sigmoid）得到新的隐藏状态和输出。\n",
    "\n",
    "然而，传统的 RNN 存在**梯度消失**和**梯度爆炸**等问题，导致在处理长序列时难以有效地传递信息。为了解决这个问题，产生了一些改进的 RNN 变体，如长短时记忆网络（LSTM）和门控循环单元（GRU），它们引入了门控机制，更好地捕捉序列中的长距离依赖。\n",
    "\n",
    "## 应用领域\n",
    "\n",
    "RNN 在许多领域都有广泛的应用：\n",
    "\n",
    "- **自然语言处理（NLP）**：RNN 可以用于文本生成、语言建模、机器翻译、文本分类和情感分析等任务。\n",
    "- **语音识别**：RNN 可以处理音频数据，用于语音识别、语音合成等。\n",
    "- **时间序列预测**：RNN 被应用于股票价格预测、天气预测、交通流量预测等。\n",
    "- **图像描述生成**：结合卷积神经网络（CNN），RNN 可以生成图像描述。\n",
    "- **视频分析**：RNN 可用于动作识别、视频标注等。\n",
    "\n",
    "## 实现工具与库\n",
    "\n",
    "许多深度学习框架提供了对 RNN 及其变体的支持，包括 TensorFlow、PyTorch、Keras 等。这些框架提供了高级的接口，帮助您构建、训练和部署 RNN 模型。使用 GPU 可以加速训练过程。\n",
    "\n",
    "## 总结\n",
    "\n",
    "循环神经网络是一种强大的神经网络模型，专门用于处理序列数据。通过引入循环结构和记忆机制，RNN 可以在序列数据中捕捉时间相关性，使其在多个应用领域都取得了卓越的成果。尽管传统的 RNN 存在一些问题，但通过改进的变体如 LSTM 和 GRU，我们能够更好地解决长序列的依赖关系。\n",
    "\n",
    "如需进一步了解如何使用 RNN，您可以查看相关的教程和实际代码示例。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人名分类示例\n",
    "\n",
    "以下示例展示了如何使用循环神经网络（RNN）实现人名的分类任务。该任务的目标是根据输入的任意长度的姓名（字符串），预测姓名来自哪个国家（18 个类别）。\n",
    "\n",
    "### 数据预处理\n",
    "\n",
    "数据来源：[下载链接](http://download.pytorch.org/tutorial/data.zip)\n",
    "\n",
    "对于每个字符，我们首先将其转换为 one-hot 向量，表示为 [0,0,...,1,...,0] 的形式。然后，我们使用 RNN 进行处理。在迭代训练过程中，我们采取以下步骤：\n",
    "\n",
    "1. 随机选择一个标签（国家类别）和一个姓名。\n",
    "2. 将姓名转换为形状为 [length, 1, 57] 的 one-hot 张量，其中 length 表示姓名长度。将标签也转换为形状为 [1] 的张量。\n",
    "3. 初始化隐藏层状态信息。\n",
    "4. 循环遍历姓名中的每个字符的 one-hot 向量，将其输入到 RNN 中。\n",
    "5. 得到输出，即预测的 18 个分类。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data\n",
    "from common_tools import set_seed\n",
    "import enviroments\n",
    "\n",
    "set_seed(1)  # 设置随机种子\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters)\n",
    "\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)                 # 选类别\n",
    "    line = randomChoice(category_lines[category])           # 选一个样本\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)    # str to one-hot\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line))\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "\n",
    "\n",
    "def get_lr(iter, learning_rate):\n",
    "    lr_iter = learning_rate if iter < n_iters else learning_rate*0.1\n",
    "    return lr_iter\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.u = nn.Linear(input_size, hidden_size)\n",
    "        self.w = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "\n",
    "        u_x = self.u(inputs)\n",
    "\n",
    "        hidden = self.w(hidden)\n",
    "        hidden = self.tanh(hidden + u_x)\n",
    "\n",
    "        output = self.softmax(self.v(hidden))\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    line_tensor = line_tensor.to(device)\n",
    "    hidden = hidden.to(device)\n",
    "    category_tensor = category_tensor.to(device)\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # config\n",
    "    path_txt = os.path.join(enviroments.names,\"*.txt\")\n",
    "    all_letters = string.ascii_letters + \" .,;'\"\n",
    "    n_letters = len(all_letters)    # 52 + 5 字符总数\n",
    "    print_every = 5000\n",
    "    plot_every = 5000\n",
    "    learning_rate = 0.005\n",
    "    n_iters = 200000\n",
    "\n",
    "    # step 1 data\n",
    "    # Build the category_lines dictionary, a list of names per language\n",
    "    category_lines = {}\n",
    "    all_categories = []\n",
    "    for filename in glob.glob(path_txt):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        all_categories.append(category)\n",
    "        lines = readLines(filename)\n",
    "        category_lines[category] = lines\n",
    "\n",
    "    n_categories = len(all_categories)\n",
    "\n",
    "    # step 2 model\n",
    "    n_hidden = 128\n",
    "    # rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "    rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "\n",
    "    rnn.to(device)\n",
    "\n",
    "    # step 3 loss\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # step 4 optimize by hand\n",
    "\n",
    "    # step 5 iteration\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    start = time.time()\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # sample\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "\n",
    "        # training\n",
    "        output, loss = train(category_tensor, line_tensor)\n",
    "\n",
    "        current_loss += loss\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iter % print_every == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('Iter: {:<7} time: {:>8s} loss: {:.4f} name: {:>10s}  pred: {:>8s} label: {:>8s}'.format(\n",
    "                iter, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iter % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0\n",
    "path_model = os.path.join(BASE_DIR, \"rnn_state_dict.pkl\")\n",
    "torch.save(rnn.state_dict(), path_model)\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "\n",
    "predict('Yue Tingsong')\n",
    "predict('Yue tingsong')\n",
    "predict('yutingsong')\n",
    "\n",
    "predict('test your name')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
